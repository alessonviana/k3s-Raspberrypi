# k3s Cluster Deployment on Raspberry Pi 4

This Ansible project automates the installation and configuration of a k3s cluster on Raspberry Pi 4.

## üìã Table of Contents

- [Prerequisites](#-prerequisites)
- [Project Structure](#-project-structure)
- [Initial Configuration](#-initial-configuration)
- [Quick Start Guide](#-quick-start-guide)
- [Advanced Configuration](#-advanced-configuration)
- [Post-Deployment Verification](#-post-deployment-verification)
- [Security](#-security)
- [Troubleshooting](#-troubleshooting)
- [Additional Resources](#-additional-resources)

## üìã Prerequisites

### On your local computer (control machine)

- Ansible installed (version 2.9 or higher)
- Python 3
- SSH access to Raspberry Pi machines
- Network connection to the machines

**Installing Ansible and dependencies:**

```bash
# Ubuntu/Debian
sudo apt update
sudo apt install ansible sshpass

# macOS
brew install ansible
brew install hudochenkov/sshpass/sshpass

# Via pip
pip3 install ansible
# sshpass needs to be installed separately (apt/brew)
```

**Note:** `sshpass` is required for Ansible to use SSH passwords from the inventory. Without it, you'll need to use `--ask-pass` or configure SSH keys.

### On Raspberry Pi machines

- Raspberry Pi OS (or another Debian-based Linux distribution)
- User with sudo privileges
- Network connection configured
- SSH enabled

## üèóÔ∏è Project Structure

```
.
‚îú‚îÄ‚îÄ ansible.cfg              # Ansible configuration
‚îú‚îÄ‚îÄ inventory/
‚îÇ   ‚îú‚îÄ‚îÄ hosts.yml           # Machine inventory (generated by script - NOT committed)
‚îÇ   ‚îî‚îÄ‚îÄ hosts.yml.example   # Inventory example (can be committed)
‚îú‚îÄ‚îÄ group_vars/
‚îÇ   ‚îú‚îÄ‚îÄ all.yml             # Global variables (generated by script)
‚îÇ   ‚îî‚îÄ‚îÄ k3s_cluster.yml     # k3s cluster variables (generated by script)
‚îú‚îÄ‚îÄ playbooks/
‚îÇ   ‚îú‚îÄ‚îÄ site.yml            # Main playbook
‚îÇ   ‚îú‚îÄ‚îÄ k3s-master.yml      # Master installation
‚îÇ   ‚îî‚îÄ‚îÄ k3s-workers.yml    # Workers installation
‚îú‚îÄ‚îÄ scripts/
‚îÇ   ‚îú‚îÄ‚îÄ setup-inventory.sh  # Interactive configuration script
‚îÇ   ‚îî‚îÄ‚îÄ setup-ssh-keys.sh   # Script to configure SSH keys
‚îî‚îÄ‚îÄ README.md               # This documentation
```

‚ö†Ô∏è **Important**: The `inventory/hosts.yml` file contains sensitive information (IPs, users) and is in `.gitignore` to prevent it from being committed to GitHub.

## ‚öôÔ∏è Initial Configuration

### 1. Configure Inventory (Interactive Script)

Run the interactive script that will collect all necessary information:

```bash
./scripts/setup-inventory.sh
```

The script will ask:

- **Number of nodes:**
  - How many masters do you want to configure? (default: `1`)
  - How many workers do you want to configure? (default: `2`)

- **For each Master:**
  - Master name (default: `master01`, `master02`, etc.)
  - Master IP
  - SSH user (default: `pi` for the first, then uses the same)
  - SSH password (requested securely)
  - SSH port (default: `22`)

- **For each Worker:**
  - Worker name (default: `worker01`, `worker02`, etc.)
  - Worker IP
  - SSH user (default: same as first master)
  - SSH password (requested securely)
  - SSH port (default: `22`)

- **General settings:**
  - Timezone (default: `America/Toronto`)
  - k3s version (default: empty for latest stable)
  - Flannel backend (default: `vxlan`)

The script will automatically generate:
- `inventory/hosts.yml` - Ansible inventory (‚ö†Ô∏è **WILL NOT be committed** - contains IPs and users)
- `inventory/.passwords.yml` - SSH passwords file (‚ö†Ô∏è **WILL NOT be committed** - contains passwords)
- `group_vars/all.yml` - Global variables
- `group_vars/k3s_cluster.yml` - k3s cluster variables

üîí **Security**: The files `inventory/hosts.yml` and `inventory/.passwords.yml` are in `.gitignore` and will not be committed to GitHub, as they contain sensitive information (IPs, users, SSH ports and passwords).

**Example execution:**

```bash
$ ./scripts/setup-inventory.sh

üöÄ k3s Inventory Configuration
==================================

üìã Initial Configuration
----------------------
How many masters do you want to configure? [1]: 
How many workers do you want to configure? [2]: 

üìã Masters Configuration (main nodes)
---------------------------------------------

Master #1:
  Master name [master01]: 
  Master IP: 192.168.2.111
  SSH user [pi]: 
  SSH password: 
  SSH port [22]: 

üìã Workers Configuration (worker nodes)
-----------------------------------------------

Worker #1:
  Worker name [worker01]: 
  Worker IP: 192.168.2.112
  SSH user [pi]: 
  SSH password: 
  SSH port [22]: 

Worker #2:
  Worker name [worker02]: 
  Worker IP: 192.168.2.113
  SSH user [pi]: 
  SSH password: 
  SSH port [22]: 
...
```

### 2. Configure SSH Keys (Recommended)

To avoid typing passwords on each execution, configure SSH keys:

**Using the script:**

```bash
./scripts/setup-ssh-keys.sh
```

**Or manually:**

```bash
ssh-copy-id user@master-ip
ssh-copy-id user@worker1-ip
ssh-copy-id user@worker2-ip
```

## üöÄ Quick Start Guide

### Step 1: Configure the Inventory

Run the configuration script:

```bash
./scripts/setup-inventory.sh
```

### Step 2: Install sshpass (if necessary)

If you use passwords in the inventory, Ansible needs `sshpass`:

```bash
# Ubuntu/Debian
sudo apt install sshpass

# macOS
brew install hudochenkov/sshpass/sshpass
```

### Step 3: Test Connectivity

Before running the deployment, test connectivity with all machines:

```bash
# With passwords in inventory (requires sshpass)
ansible all -m ping

# With SSH keys configured
ansible all -m ping

# Without passwords in inventory and without keys (password will be requested)
ansible all -m ping --ask-pass
```

### Step 4: Run the Deployment

**Option A: Complete Deployment (Recommended)**

```bash
# With SSH keys configured
ansible-playbook playbooks/site.yml

# Without SSH keys
ansible-playbook playbooks/site.yml --ask-pass --ask-become-pass
```

**Option B: Step-by-Step Deployment**

1. **Install the master first:**

```bash
ansible-playbook playbooks/k3s-master.yml --ask-pass --ask-become-pass
```

2. **Wait for the master to start (30-60 seconds)**

3. **Install the workers:**

```bash
ansible-playbook playbooks/k3s-workers.yml --ask-pass --ask-become-pass
```

### Step 5: Verify the Cluster

‚ú® **The kubeconfig has already been automatically copied to `~/.kube/k3s-config`!**

**Use the kubeconfig locally:**

```bash
# Export temporarily
export KUBECONFIG=~/.kube/k3s-config
kubectl get nodes

# Or make it permanent (add to ~/.bashrc or ~/.zshrc)
echo 'export KUBECONFIG=$HOME/.kube/k3s-config' >> ~/.bashrc
source ~/.bashrc
```

**Verify the cluster:**

```bash
# View nodes
kubectl get nodes

# View system pods
kubectl get pods -n kube-system

# Check cluster status
kubectl cluster-info

# View all resources
kubectl get all --all-namespaces
```

**Access directly on the master (optional):**

```bash
ssh user@master-ip
sudo kubectl get nodes
```

### Automatic Features

Upon completing the deployment, the playbook automatically:

- ‚úÖ Copies the kubeconfig from the master to your local machine at `~/.kube/k3s-config`
- ‚úÖ Configures the correct master IP in the kubeconfig
- ‚úÖ Sets the correct permissions (0600)
- ‚úÖ Displays instructions on how to use the kubeconfig

You'll see a message at the end of the playbook with the file path and how to use it!

## üîß Advanced Configuration

### Edit Settings Manually

After running the configuration script, you can manually edit the generated files:

**Inventory (`inventory/hosts.yml`):**
- Add/remove machines
- Change IPs and users

**Global Variables (`group_vars/all.yml`):**
- Timezone
- Default user
- SSH settings

**Cluster Variables (`group_vars/k3s_cluster.yml`):**
- k3s version (`k3s_version`)
- Flannel backend (`k3s_flannel_backend`: `vxlan` or `host-gw`)
- Extra k3s arguments (`k3s_extra_args`)
- Master IPs and URLs

### Run Individual Playbooks

**Master only:**

```bash
ansible-playbook playbooks/k3s-master.yml --ask-pass --ask-become-pass
```

**Workers only** (after master is installed):

```bash
ansible-playbook playbooks/k3s-workers.yml --ask-pass --ask-become-pass
```

## ‚úÖ Post-Deployment Verification

### Install kubectl locally (if necessary)

```bash
# Linux
curl -LO "https://dl.k8s.io/release/$(curl -L -s https://dl.k8s.io/release/stable.txt)/bin/linux/amd64/kubectl"
sudo install -o root -g root -m 0755 kubectl /usr/local/bin/kubectl

# macOS
brew install kubectl
```

### Useful kubectl commands

```bash
# View nodes and status
kubectl get nodes -o wide

# View pods in all namespaces
kubectl get pods --all-namespaces

# Describe a node
kubectl describe node master01

# View logs of a pod
kubectl logs <pod-name> -n <namespace>

# Execute command in a pod
kubectl exec -it <pod-name> -n <namespace> -- /bin/sh
```

## üîí Security

### Implemented Best Practices

1. ‚úÖ Restricted permissions on kubeconfig (0600)
2. ‚úÖ Use of variables for configurations
3. ‚úÖ Interactive script for secure configuration
4. ‚úÖ Inventory and passwords protected in `.gitignore` (not committed)
5. ‚úÖ Example file available (`hosts.yml.example`)
6. ‚úÖ Passwords requested securely (not displayed on screen)

### Additional Recommendations

1. **Configure SSH keys** to avoid using passwords
2. **Review permissions** of sensitive files
3. **Configure firewall** on Raspberry Pi to allow only necessary ports
4. **Rotate k3s tokens** periodically
5. **Keep k3s updated** with recent versions

## üêõ Troubleshooting

### Problem: Cannot connect to machines

**Symptoms:** SSH connection error or "Connection refused"

**Solution:** Check:
- Network connectivity (ping the machines)
- SSH enabled on Raspberry Pi
- Firewall not blocking port 22

```bash
# Test connectivity
ping <machine-ip>
ssh user@<machine-ip>
```

### Problem: Workers cannot join the cluster

**Symptoms:** Workers do not appear in `kubectl get nodes`

**Solution:** Check:
- k3s token was generated correctly on the master
- Connectivity between master and workers (port 6443)
- Firewall allowing communication between nodes
- Master is running: `sudo systemctl status k3s` on the master

```bash
# Check token on master
sudo cat /var/lib/rancher/k3s/server/node-token

# Check connectivity between nodes
ping <master-ip>  # from worker to master
```

### Problem: k3s does not start

**Symptoms:** k3s service fails to start

**Solution:**

```bash
# On the node with the problem
sudo systemctl status k3s        # or k3s-agent for workers
sudo journalctl -u k3s -f        # real-time logs
sudo journalctl -u k3s -n 100     # last 100 log lines
```

### Problem: k3s token not found

**Symptoms:** Error when running workers playbook

**Solution:** Run the master playbook first and wait for it to start completely (30-60 seconds).

### Problem: Permission denied

**Symptoms:** Permission error when running playbooks

**Solution:** Configure SSH keys or use authentication flags:

```bash
ansible-playbook playbooks/site.yml --ask-pass --ask-become-pass
```

### Problem: kubeconfig was not copied

**Symptoms:** File `~/.kube/k3s-config` does not exist

**Solution:**
1. Check if the master playbook ran successfully
2. Check if the file exists on the master: `ls -la /home/user/.kube/config`
3. Manually copy:

```bash
mkdir -p ~/.kube
scp user@<master-ip>:~/.kube/config ~/.kube/k3s-config
chmod 600 ~/.kube/k3s-config
```

### Problem: Configuration script does not work

**Symptoms:** Error when running `setup-inventory.sh`

**Solution:**
1. Check if the script has execution permission: `chmod +x scripts/setup-inventory.sh`
2. Check if you're using bash: `bash scripts/setup-inventory.sh`
3. Check if directories exist: `mkdir -p inventory group_vars`

## üìö Additional Resources

- [Official k3s documentation](https://docs.k3s.io/)
- [Ansible documentation](https://docs.ansible.com/)
- [Kubernetes Documentation](https://kubernetes.io/docs/)


---

**üí° Tip**: Run the `setup-inventory.sh` script whenever you need to reconfigure the cluster or add new nodes!
